#!/usr/bin/env python3
"""
NNStreamer æ ¸å¿ƒæ¨¡çµ„
åŒ…å« NNStreamer ä¸»è¦é¡åˆ¥å’Œæ•ˆèƒ½ç›£æ§å™¨
"""

import asyncio
import cv2
import numpy as np
import time
import threading
import logging
import os
from concurrent.futures import ThreadPoolExecutor
from collections import deque
from typing import Optional, Tuple, List, Dict, Any
import psutil
import gc

# è¨­å®šæ—¥èªŒ
def setup_logging():
    """è¨­å®šæ—¥èªŒé…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s] %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('nnstreamer.log', mode='w', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

class SlidingWindowController:
    """æ»‘å‹•çª—å£å¹€æ§åˆ¶å™¨ - è™•ç†workeré€Ÿåº¦è®ŠåŒ–"""
    
    def __init__(self, window_size: int = 10):
        self.window_size = window_size
        self.recent_decisions = deque(maxlen=window_size)
        self.startup_frames = 0  # å•Ÿå‹•éšæ®µè¨ˆæ•¸å™¨
        self.startup_threshold = 30  # å•Ÿå‹•éšæ®µå¹€æ•¸
        
    def should_process_frame(self, queue_usage: float) -> bool:
        """åŸºæ–¼éšŠåˆ—å£“åŠ›å‹•æ…‹æ±ºç­–æ˜¯å¦è™•ç†å¹€"""
        self.startup_frames += 1
        
        # å•Ÿå‹•éšæ®µï¼šè™•ç†æ‰€æœ‰å¹€ï¼Œè®“ç³»çµ±ç©©å®š
        if self.startup_frames <= self.startup_threshold:
            self.recent_decisions.append(1)
            return True
        
        # æ›´æº«å’Œçš„ç›®æ¨™è¨ˆç®—ï¼šé¿å…éåº¦æ¿€é€²
        # åªæœ‰ç•¶éšŠåˆ—ä½¿ç”¨ç‡è¶…é70%æ™‚æ‰é–‹å§‹æ¸›å°‘è™•ç†
        if queue_usage <= 0.7:
            target_keep_ratio = 1.0  # æ­£å¸¸è™•ç†æ‰€æœ‰å¹€
        else:
            # ç•¶éšŠåˆ—ä½¿ç”¨ç‡ > 70% æ™‚ï¼Œé€æ¼¸æ¸›å°‘è™•ç†
            # ä½¿ç”¨å¹³æ–¹æ ¹å‡½æ•¸ä½¿è®ŠåŒ–æ›´å¹³ç·©
            pressure = (queue_usage - 0.7) / 0.3  # å°‡70%-100%æ˜ å°„åˆ°0-1
            target_keep_ratio = max(0.3, 1.0 - (pressure ** 0.5) * 0.7)
        
        # è¨ˆç®—æœ€è¿‘çš„å¯¦éš›è™•ç†æ¯”ç‡
        if len(self.recent_decisions) == 0:
            current_ratio = 1.0  # åˆå§‹ç‹€æ…‹ï¼šè™•ç†æ‰€æœ‰å¹€
        else:
            current_ratio = sum(self.recent_decisions) / len(self.recent_decisions)
        
        # æ›´ä¿å®ˆçš„æ±ºç­–ï¼šåªæœ‰ç•¶æ˜é¡¯è¶…å‡ºç›®æ¨™æ™‚æ‰æ¸›å°‘è™•ç†
        should_process = current_ratio <= target_keep_ratio * 1.1  # 10%å®¹å¿åº¦
        
        # è¨˜éŒ„æ±ºç­–åˆ°æ»‘å‹•çª—å£
        self.recent_decisions.append(1 if should_process else 0)
        
        return should_process

class PerformanceMonitor:
    """æ•ˆèƒ½ç›£æ§å™¨"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.inference_times = deque(maxlen=window_size)
        self.display_timestamps = deque(maxlen=window_size)  # é¡¯ç¤ºæ™‚é–“æˆ³
        self.cpu_readings = deque(maxlen=20)  # CPU ä½¿ç”¨ç‡ç§»å‹•çª—å£ (20å€‹æ¨£æœ¬)
        self.start_time = None  # ç³»çµ±å•Ÿå‹•æ™‚é–“
        self.total_displayed_frames = 0  # å¯¦éš›é¡¯ç¤ºçš„å¹€æ•¸
        
    def add_inference_time(self, inference_time: float):
        """æ·»åŠ æ¨è«–æ™‚é–“"""
        self.inference_times.append(inference_time)
        
    def add_display_sample(self):
        """æ·»åŠ é¡¯ç¤ºæ¨£æœ¬ - æ¯æ¬¡å¯¦éš›é¡¯ç¤ºå¹€æ™‚èª¿ç”¨"""
        current_time = time.time()
        
        if self.start_time is None:
            self.start_time = current_time
            
        self.display_timestamps.append(current_time)
        self.total_displayed_frames += 1
        
        # åŒæ™‚æ·»åŠ CPUä½¿ç”¨ç‡æ¨£æœ¬
        self.cpu_readings.append(psutil.cpu_percent())
        
    def get_avg_inference_time(self) -> float:
        """ç²å–å¹³å‡æ¨è«–æ™‚é–“"""
        return np.mean(self.inference_times) if self.inference_times else 0.0
        
    def get_fps(self) -> float:
        """ç²å–å¯¦éš›é¡¯ç¤ºFPS"""
        if len(self.display_timestamps) < 2:
            return 0.0
            
        # åŸºæ–¼æœ€è¿‘æ™‚é–“çª—å£è¨ˆç®—
        recent_window = min(30, len(self.display_timestamps))  # æœ€è¿‘30å¹€
        if recent_window < 2:
            return 0.0
            
        time_span = self.display_timestamps[-1] - self.display_timestamps[-recent_window]
        if time_span <= 0:
            return 0.0
            
        return (recent_window - 1) / time_span
        
    def get_overall_fps(self) -> float:
        """ç²å–æ•´é«”å¹³å‡FPS"""
        if self.start_time is None or self.total_displayed_frames < 2:
            return 0.0
            
        elapsed_time = time.time() - self.start_time
        if elapsed_time <= 0:
            return 0.0
            
        return self.total_displayed_frames / elapsed_time
        
    def get_avg_cpu_percent(self) -> float:
        """ç²å–ç§»å‹•çª—å£å¹³å‡CPUä½¿ç”¨ç‡"""
        if len(self.cpu_readings) == 0:
            return psutil.cpu_percent()
        return np.mean(self.cpu_readings)
    def get_system_stats(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±çµ±è¨ˆè³‡è¨Š"""
        return {
            'cpu_percent': self.get_avg_cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'avg_inference_ms': self.get_avg_inference_time() * 1000,
            'fps': self.get_fps(),
            'overall_fps': self.get_overall_fps()
        }


class NNStreamer:
    """
    NNStreamer ä¸»è¦é¡åˆ¥
    å¯¦ç¾é«˜æ•ˆçš„æ¨¡å‹ä¸²æµæ¨è«–æ¶æ§‹
    """
    
    def __init__(self, 
                 interpreter_class,
                 model_path: str,
                 input_source: str = None,
                 max_workers: int = 4,
                 queue_size: int = 32,
                 display_output: bool = True,
                 enable_auto_tuning: bool = False):
        
        self.interpreter_class = interpreter_class
        self.model_path = model_path
        self.input_source = input_source or 0  # é è¨­ä½¿ç”¨æ”å½±æ©Ÿ
        self.max_workers = max_workers
        self.queue_size = queue_size
        self.display_output = display_output
        self.enable_auto_tuning = enable_auto_tuning
        
        # æ€§èƒ½èª¿å„ªåƒæ•¸
        self.frame_timeout = 0.1  # å¹€éšŠåˆ—è¶…æ™‚æ™‚é–“
        self.result_timeout = 0.1  # çµæœéšŠåˆ—è¶…æ™‚æ™‚é–“
        self.frame_skip_interval = 1  # å¹€è·³éé–“éš”
        self.frame_counter = 0  # å¹€è¨ˆæ•¸å™¨
        
        # çµ±è¨ˆè¨ˆæ•¸å™¨
        self.total_frames = 0
        self.dropped_frames = 0
        self.dropped_results = 0
        
        # å¹€é †åºæ§åˆ¶
        self.next_display_frame_id = 0  # ä¸‹ä¸€å€‹æ‡‰è©²é¡¯ç¤ºçš„å¹€ID
        self.pending_results = {}  # ç­‰å¾…é¡¯ç¤ºçš„çµæœ {frame_id: result}
        self.max_pending_frames = 10  # æœ€å¤§ç­‰å¾…å¹€æ•¸ï¼Œé˜²æ­¢è¨˜æ†¶é«”ç´¯ç©
        
        # æ»‘å‹•çª—å£æ§åˆ¶å™¨
        self.window_controller = SlidingWindowController(window_size=8)
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.interpreters = {}
        self.executor = ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="AI-Worker")
        self.performance_monitor = PerformanceMonitor()
        
        # ç•°æ­¥éšŠåˆ—
        self.frame_queue = None
        self.result_queue = None
        
        # æ§åˆ¶ç‹€æ…‹
        self.should_stop = False
        self.is_running = False
        
        # åˆå§‹åŒ–ç³»çµ±
        self._initialize_system()
        
    def _initialize_system(self):
        """åˆå§‹åŒ–ç³»çµ±çµ„ä»¶"""
        logger.info("=== NNStreamer ç³»çµ±å•Ÿå‹• ===")
        logger.info(f"æ¨¡å‹: {self.model_path}")
        logger.info(f"è¼¸å…¥ä¾†æº: {self.input_source}")
        logger.info(f"æœ€å¤§å·¥ä½œè€…æ•¸: {self.max_workers}")
        
        # é è¼‰å…¥è§£é‡‹å™¨
        self._preload_interpreters()
        
    def _preload_interpreters(self):
        """é è¼‰å…¥è§£é‡‹å™¨"""
        logger.info("é è¼‰å…¥è§£é‡‹å™¨...")
        
        # ç‚ºæ¯å€‹å·¥ä½œè€…å‰µå»ºç¨ç«‹çš„è§£é‡‹å™¨
        for i in range(self.max_workers):
            thread_id = f"worker_{i}"
            self.interpreters[thread_id] = self.interpreter_class(
                model_path=self.model_path
            )
            
        logger.info(f"æˆåŠŸé è¼‰å…¥ {len(self.interpreters)} å€‹è§£é‡‹å™¨")
        
    def get_interpreter_for_thread(self):
        """ç²å–å°æ‡‰åŸ·è¡Œç·’çš„è§£é‡‹å™¨"""
        thread_id = threading.current_thread().name
        
        # å¦‚æœç•¶å‰åŸ·è¡Œç·’æ²’æœ‰å°æ‡‰è§£é‡‹å™¨ï¼Œå‰µå»ºæ–°çš„
        if thread_id not in self.interpreters:
            worker_keys = [k for k in self.interpreters.keys() if k.startswith("worker_")]
            if worker_keys:
                # é‡ç”¨é è¼‰å…¥çš„è§£é‡‹å™¨
                available_key = worker_keys[0]
                self.interpreters[thread_id] = self.interpreters.pop(available_key)
            else:
                # å‰µå»ºæ–°è§£é‡‹å™¨
                self.interpreters[thread_id] = self.interpreter_class(
                    model_path=self.model_path
                )
                
        return self.interpreters[thread_id]
        
    async def frame_producer(self, source):
        """å½±åƒå¹€ç”Ÿç”¢è€…å”ç¨‹"""
        logger.info(f"å•Ÿå‹•å½±åƒæ“·å–å™¨: {source}")
        
        if isinstance(source, str) and source.isdigit():
            cap = cv2.VideoCapture(int(source))
        else:
            cap = cv2.VideoCapture(source)
            
        if not cap.isOpened():
            logger.error(f"ç„¡æ³•é–‹å•Ÿå½±åƒä¾†æº: {source}")
            return
            
        frame_count = 0
        try:
            while not self.should_stop:
                ret, frame = cap.read()
                if not ret:
                    if isinstance(source, str) and source != "0":
                        logger.info("å½±ç‰‡æ’­æ”¾å®Œç•¢")
                        break
                    else:
                        continue
                
                self.total_frames += 1
                
                # ä½¿ç”¨æ»‘å‹•çª—å£æ§åˆ¶å™¨å‹•æ…‹æ±ºç­–
                queue_usage = self.frame_queue.qsize() / self.queue_size
                
                if not self.window_controller.should_process_frame(queue_usage):
                    self.dropped_frames += 1
                    continue
                        
                # å°‡å¹€æ”¾å…¥éšŠåˆ—
                try:
                    await asyncio.wait_for(
                        self.frame_queue.put((frame_count, frame)), 
                        timeout=self.frame_timeout
                    )
                    frame_count += 1
                except asyncio.TimeoutError:
                    self.dropped_frames += 1
                    drop_rate = (self.dropped_frames / self.total_frames) * 100
                    logger.warning(f"å¹€éšŠåˆ—å·²æ»¿ï¼Œè·³éå¹€ (ä¸Ÿå¹€ç‡: {drop_rate:.1f}%)")
                    
                    # è‡ªå‹•èª¿æ•´å»ºè­°
                    if self.enable_auto_tuning and drop_rate > 10:
                        logger.info("ğŸ”§ èª¿å„ªå»ºè­°: è€ƒæ…®å¢åŠ  --queue_size åƒæ•¸æˆ–æ¸›å°‘ --workers æ•¸é‡")
                    continue
                    
        except Exception as e:
            logger.error(f"å½±åƒæ“·å–éŒ¯èª¤: {e}")
        finally:
            cap.release()
            # ç™¼é€çµæŸä¿¡è™Ÿ
            await self.frame_queue.put(None)
            logger.info("å½±åƒæ“·å–å™¨åœæ­¢")
            
    def sync_inference(self, frame_data: Tuple[int, np.ndarray]) -> Optional[Tuple[int, np.ndarray, Any]]:
        """åŒæ­¥æ¨è«–å‡½æ•¸ï¼ˆåœ¨åŸ·è¡Œç·’ä¸­é‹è¡Œï¼‰"""
        frame_id, frame = frame_data
        
        try:
            # ç²å–è§£é‡‹å™¨
            interpreter = self.get_interpreter_for_thread()
            
            # åŸ·è¡Œæ¨è«–
            start_time = time.time()
            result = interpreter.inference(frame)
            
            # è¨˜éŒ„æ¨è«–æ™‚é–“
            inference_time = time.time() - start_time
            self.performance_monitor.add_inference_time(inference_time)
            
            return frame_id, frame, result
            
        except Exception as e:
            logger.error(f"æ¨è«–å¤±æ•— (Frame {frame_id}): {e}")
            return None
            
    async def inference_manager(self):
        """æ¨è«–ç®¡ç†å™¨å”ç¨‹"""
        logger.info("å•Ÿå‹•æ¨è«–ç®¡ç†å™¨")
        
        active_tasks = set()
        
        try:
            while not self.should_stop:
                # å¾å¹€éšŠåˆ—ç²å–æ•¸æ“š
                frame_data = await self.frame_queue.get()
                
                if frame_data is None:
                    logger.info("æ”¶åˆ°çµæŸä¿¡è™Ÿ")
                    break
                    
                # å‰µå»ºæ¨è«–ä»»å‹™
                loop = asyncio.get_event_loop()
                task = loop.run_in_executor(
                    self.executor, 
                    self.sync_inference, 
                    frame_data
                )
                active_tasks.add(task)
                
                # è™•ç†å®Œæˆçš„ä»»å‹™
                done_tasks = [t for t in active_tasks if t.done()]
                for task in done_tasks:
                    active_tasks.remove(task)
                    result = await task
                    
                    if result is not None:
                        try:
                            # å°‡çµæœæ”¾å…¥éšŠåˆ—ï¼Œä½†ä¸ç«‹å³è™•ç†é †åº
                            await asyncio.wait_for(
                                self.result_queue.put(result),
                                timeout=0.05
                            )
                        except asyncio.TimeoutError:
                            self.dropped_results += 1
                            logger.warning("çµæœéšŠåˆ—å·²æ»¿ï¼Œä¸Ÿæ£„çµæœ")
                            if self.enable_auto_tuning:
                                logger.info("ğŸ”§ èª¿å„ªå»ºè­°: è€ƒæ…®å¢åŠ  --workers æ•¸é‡æˆ–ç°¡åŒ– visualize() æ–¹æ³•")
                            
                # é™åˆ¶åŒæ™‚é€²è¡Œçš„ä»»å‹™æ•¸é‡
                while len(active_tasks) >= self.max_workers:
                    done, active_tasks = await asyncio.wait(
                        active_tasks,
                        return_when=asyncio.FIRST_COMPLETED
                    )
                    
                    for task in done:
                        result = await task
                        if result is not None:
                            try:
                                await asyncio.wait_for(
                                    self.result_queue.put(result),
                                    timeout=self.result_timeout
                                )
                            except asyncio.TimeoutError:
                                self.dropped_results += 1
                                logger.warning("çµæœéšŠåˆ—å·²æ»¿ï¼Œä¸Ÿæ£„çµæœ")
                                if self.enable_auto_tuning:
                                    logger.info("ğŸ”§ èª¿å„ªå»ºè­°: è€ƒæ…®å¢åŠ  --workers æ•¸é‡æˆ–ç°¡åŒ– visualize() æ–¹æ³•")
                                    
        except Exception as e:
            logger.error(f"æ¨è«–ç®¡ç†å™¨éŒ¯èª¤: {e}")
        finally:
            # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
            if active_tasks:
                await asyncio.gather(*active_tasks, return_exceptions=True)
            logger.info("æ¨è«–ç®¡ç†å™¨åœæ­¢")
            
    async def result_consumer(self):
        """çµæœæ¶ˆè²»è€…å”ç¨‹ - ä½¿ç”¨è§£é‡‹å™¨çš„è¦–è¦ºåŒ–æ–¹æ³•ï¼Œä¿è­‰å¹€é †åº"""
        logger.info("å•Ÿå‹•çµæœè™•ç†å™¨")
        
        if self.display_output:
            cv2.namedWindow("NNStreamer Output", cv2.WINDOW_AUTOSIZE)
            
        # ç²å–ä¸€å€‹è§£é‡‹å™¨ç”¨æ–¼ç¹ªåœ–
        interpreter = list(self.interpreters.values())[0]
            
        try:
            while not self.should_stop:
                try:
                    # ç²å–æ¨è«–çµæœ
                    result = await asyncio.wait_for(
                        self.result_queue.get(),
                        timeout=1.0
                    )
                    
                    if result is None:
                        break
                        
                    frame_id, frame, model_result = result
                    
                    # å°‡çµæœå­˜å…¥å¾…è™•ç†å­—å…¸
                    self.pending_results[frame_id] = (frame, model_result)
                    
                    # æŒ‰é †åºè™•ç†å¯ä»¥é¡¯ç¤ºçš„å¹€
                    while self.next_display_frame_id in self.pending_results:
                        display_frame, display_result = self.pending_results.pop(self.next_display_frame_id)
                        
                        # æ›´æ–°æ•ˆèƒ½ç›£æ§ - è¨˜éŒ„å¯¦éš›é¡¯ç¤º
                        self.performance_monitor.add_display_sample()
                        
                        # ä½¿ç”¨è§£é‡‹å™¨çš„è¦–è¦ºåŒ–æ–¹æ³•
                        if hasattr(interpreter, 'visualize'):
                            annotated_frame = interpreter.visualize(display_frame, display_result)
                        else:
                            # å›é€€åˆ°åŸºæœ¬é¡¯ç¤º
                            annotated_frame = display_frame
                        
                        # ç²å–çµ±è¨ˆè³‡è¨Š
                        stats = self.performance_monitor.get_system_stats()
                        
                        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
                        info_text = [
                            f"Frame: {self.next_display_frame_id}",
                            f"FPS: {stats['fps']:.1f}",
                            f"Overall FPS: {stats['overall_fps']:.1f}",
                            f"Inference: {stats['avg_inference_ms']:.1f}ms",
                            f"CPU: {stats['cpu_percent']:.1f}%",
                            f"Memory: {stats['memory_percent']:.1f}%",
                            f"Queue: {self.frame_queue.qsize()}/{self.queue_size}",
                            f"Drop Rate: {(self.dropped_frames / max(1, self.total_frames) * 100):.1f}%",
                            f"Pending: {len(self.pending_results)}",
                            f"Controller: {'Startup' if self.window_controller.startup_frames <= self.window_controller.startup_threshold else 'Active'}"
                        ]
                        
                        for i, text in enumerate(info_text):
                            cv2.putText(annotated_frame, text, (10, 30 + i * 25),
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                        
                        # é¡¯ç¤ºå½±åƒ
                        if self.display_output:
                            cv2.imshow("NNStreamer Output", cv2.resize(annotated_frame, (720, 480)))
                            
                            # æª¢æŸ¥æŒ‰éµé€€å‡º
                            key = cv2.waitKey(1) & 0xFF
                            if key == ord('q') or key == 27:  # 'q' æˆ– ESC
                                logger.info("ä½¿ç”¨è€…è«‹æ±‚é€€å‡º")
                                self.should_stop = True
                                break
                                
                        # å®šæœŸè¨˜éŒ„çµ±è¨ˆè³‡è¨Š
                        if self.next_display_frame_id % 30 == 0:  # æ¯30å¹€è¨˜éŒ„ä¸€æ¬¡
                            stats = self.performance_monitor.get_system_stats()
                            
                            # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
                            drop_rate = (self.dropped_frames / max(1, self.total_frames)) * 100
                            result_drop_rate = (self.dropped_results / max(1, self.next_display_frame_id)) * 100
                            
                            logger.info(f"çµ±è¨ˆ - FPS: {stats['fps']:.1f}, "
                                      f"æ•´é«”FPS: {stats['overall_fps']:.1f}, "
                                      f"æ¨è«–æ™‚é–“: {stats['avg_inference_ms']:.1f}ms, "
                                      f"CPU: {stats['cpu_percent']:.1f}%, "
                                      f"è¨˜æ†¶é«”: {stats['memory_percent']:.1f}%, "
                                      f"ä¸Ÿå¹€ç‡: {drop_rate:.1f}%, "
                                      f"çµæœä¸Ÿæ£„ç‡: {result_drop_rate:.1f}%, "
                                      f"éšŠåˆ—ä½¿ç”¨ç‡: {(self.frame_queue.qsize() / self.queue_size * 100):.1f}%, "
                                      f"ç­‰å¾…å¹€æ•¸: {len(self.pending_results)}")
                            
                            # è‡ªå‹•èª¿å„ªå»ºè­°
                            if self.enable_auto_tuning:
                                self._auto_tuning_suggestions(stats, drop_rate, result_drop_rate)
                        
                        # ç§»å‹•åˆ°ä¸‹ä¸€å¹€
                        self.next_display_frame_id += 1
                        
                        # å¦‚æœé€€å‡ºå¾ªç’°å°±åœæ­¢è™•ç†
                        if self.should_stop:
                            break
                    
                    # æ¸…ç†éèˆŠçš„ç­‰å¾…å¹€ï¼Œé˜²æ­¢è¨˜æ†¶é«”ç´¯ç©
                    if len(self.pending_results) > self.max_pending_frames:
                        # ç§»é™¤æœ€èˆŠçš„å¹€
                        oldest_frames = sorted(self.pending_results.keys())[:len(self.pending_results) - self.max_pending_frames]
                        for old_frame_id in oldest_frames:
                            self.pending_results.pop(old_frame_id, None)
                            # å¦‚æœç§»é™¤çš„æ˜¯æ‡‰è©²é¡¯ç¤ºçš„å¹€ï¼Œè·³åˆ°ä¸‹ä¸€å€‹
                            if old_frame_id == self.next_display_frame_id:
                                self.next_display_frame_id = old_frame_id + 1
                        
                        logger.warning(f"æ¸…ç†éèˆŠå¹€ï¼Œè·³åˆ° frame {self.next_display_frame_id}")

                except asyncio.TimeoutError:
                    continue
                    
        except Exception as e:
            logger.error(f"çµæœè™•ç†å™¨éŒ¯èª¤: {e}")
        finally:
            if self.display_output:
                cv2.destroyAllWindows()
            logger.info("çµæœè™•ç†å™¨åœæ­¢")
            
    async def run(self):
        """é‹è¡Œ NNStreamer ä¸»å¾ªç’°"""
        if self.is_running:
            logger.warning("NNStreamer å·²åœ¨é‹è¡Œä¸­")
            return
            
        self.is_running = True
        self.should_stop = False
        
        # åˆå§‹åŒ–ç•°æ­¥éšŠåˆ—
        self.frame_queue = asyncio.Queue(maxsize=self.queue_size)
        self.result_queue = asyncio.Queue(maxsize=self.queue_size)
        
        logger.info("=== å•Ÿå‹• NNStreamer ä¸²æµè™•ç† ===")
        
        try:
            # å‰µå»ºæ‰€æœ‰å”ç¨‹ä»»å‹™
            tasks = [
                asyncio.create_task(self.frame_producer(self.input_source)),
                asyncio.create_task(self.inference_manager()),
                asyncio.create_task(self.result_consumer())
            ]
            
            # ä¸¦è¡Œé‹è¡Œæ‰€æœ‰ä»»å‹™
            await asyncio.gather(*tasks, return_exceptions=True)
            
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿ")
        except Exception as e:
            logger.error(f"é‹è¡Œæ™‚éŒ¯èª¤: {e}")
        finally:
            await self.cleanup()
            
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        logger.info("æ¸…ç†ç³»çµ±è³‡æº...")
        self.should_stop = True
        self.is_running = False
        
        # é—œé–‰åŸ·è¡Œå™¨
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)
            
        # æ¸…ç†è§£é‡‹å™¨
        self.interpreters.clear()
        
        # å¼·åˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        logger.info("è³‡æºæ¸…ç†å®Œæˆ")