{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3478c654",
   "metadata": {},
   "source": [
    "# MediaTek Genio AI é–‹ç™¼æŒ‡å—-2ï¼šTensorFlow Lite æ¨¡å‹æ•ˆèƒ½æ¸¬è©¦\n",
    "\n",
    "## ğŸ¯ é—œæ–¼é€™å€‹ç­†è¨˜æœ¬\n",
    "é€™æ˜¯ä¸€å€‹å®Œæ•´çš„æ•™å­¸ç¯„ä¾‹ï¼Œæ•™æ‚¨å¦‚ä½•åœ¨ MediaTek Genio SoCï¼ˆç³»çµ±æ™¶ç‰‡ï¼‰ä¸Šä½¿ç”¨ NeuronRT é‹è¡Œ AI æ¨¡å‹ï¼Œä¸¦æ¸¬é‡å…¶æ•ˆèƒ½ã€‚\n",
    "\n",
    "## ğŸ“š èƒŒæ™¯çŸ¥è­˜ï¼š\n",
    "- **TensorFlow Lite**ï¼šGoogle é–‹ç™¼çš„è¼•é‡ç´š AI æ¨è«–æ¡†æ¶ï¼Œå°ˆç‚ºæ‰‹æ©Ÿã€åµŒå…¥å¼è£ç½®è¨­è¨ˆï¼Œæ”¯æ´`.tflite`æ ¼å¼çš„AIæ¨¡å‹ã€‚\n",
    "- **NeuronRT**ï¼šMediaTek å…¬å¸é–‹ç™¼çš„ç¥ç¶“ç¶²è·¯æ¨è«–å¼•æ“ï¼Œå¯ä»¥åŠ é€Ÿæ¨è«–æ¡†æ¶èƒŒæ™¯çš„ AIè¨ˆç®—å·¥ä½œ\n",
    "- **MediaTek Genio SoC**ï¼šè¯ç™¼ç§‘çš„ AI è™•ç†å™¨ï¼Œå…§å»ºèˆ‡NeuronRTç›¸å®¹çš„DLAåŠVPU\n",
    "\n",
    "## ğŸ“‹ æ‚¨å°‡å­¸æœƒï¼š\n",
    "- å¦‚ä½•é€éTFLite Runtimeè¼‰å…¥å’Œé…ç½® AI æ¨¡å‹\n",
    "- å¦‚ä½•ä½¿ç”¨ NeuronRTæ–¼DLA æˆ– VPU ä¸Šé€²è¡Œ AI æ¨è«–åŠ é€Ÿ\n",
    "- å¦‚ä½•æ¸¬é‡ AI æ¨¡å‹çš„åŸ·è¡Œé€Ÿåº¦å’Œè¨˜æ†¶é«”ä½¿ç”¨é‡\n",
    "- å¦‚ä½•å°‡é€™äº›æŠ€è¡“æ•´åˆåˆ°æ‚¨çš„æ‡‰ç”¨ç¨‹å¼ä¸­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4991a",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­ç½®\n",
    "\n",
    "æˆ‘å€‘éœ€è¦åˆ‡æ›åˆ°å°ˆæ¡ˆçš„æ ¹ç›®éŒ„ï¼Œé€™æ¨£ç¨‹å¼æ‰èƒ½æ‰¾åˆ°æ¨¡å‹æª”æ¡ˆå’Œå…¶ä»–å¿…è¦çš„è³‡æºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd8bee-7d7c-47a1-961a-170560b2cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b62e2",
   "metadata": {},
   "source": [
    "## 2. åŒ¯å…¥å¿…è¦ç¨‹å¼åº«\n",
    "\n",
    "è¼‰å…¥TensorflowåŠ Python ç¨‹å¼åº«ä¾†è™•ç† AI æ¨è«–çš„å·¥ä½œæµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, warnings, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.neuronpilot.neuronrt import Interpreter\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "print(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b02a79",
   "metadata": {},
   "source": [
    "## 3. è¨­å®šæ¸¬è©¦åƒæ•¸\n",
    "\n",
    "æ ¹æ“šæ‚¨çš„ Genio å¹³å°åŠæ¸¬è©¦éœ€æ±‚ï¼Œè¨­å®šè¦ä½¿ç”¨çš„åŠ é€Ÿå™¨ã€AIæ¨¡å‹ä»¥åŠæ¸¬è©¦åƒæ•¸ã€‚\n",
    "\n",
    "### ğŸ“‹ åƒæ•¸èªªæ˜ï¼š\n",
    "- **device**ï¼šåŠ é€Ÿå™¨é¡å‹ï¼Œæ”¯æ´å¤šç¨®é¸é …ï¼š\n",
    "  - `mdla3.0`ï¼šé©ç”¨æ–¼ Genio 510/700ï¼Œä½¿ç”¨ MDLA v3.0\n",
    "  - `mdla2.0`ï¼šé©ç”¨æ–¼ Genio 1200ï¼Œä½¿ç”¨ MDLA v2.0  \n",
    "  - `vpu`ï¼šä½¿ç”¨ VPU åŠ é€Ÿå™¨é€²è¡Œæ¨ç†\n",
    "- **tflite_path**ï¼šTensorFlow Lite æ¨¡å‹æª”æ¡ˆè·¯å¾‘ï¼ˆç”¨æ–¼å–å¾—æ¨¡å‹è³‡è¨Šï¼‰\n",
    "- **dla_path**ï¼šç·¨è­¯å¥½çš„ DLA æ¨¡å‹æª”æ¡ˆè·¯å¾‘ï¼ˆç”¨æ–¼å¯¦éš›æ¨ç†ï¼‰\n",
    "\n",
    "> **ğŸ”§ å¦‚ä½•å–å¾— DLA æ¨¡å‹ï¼š**\n",
    "> \n",
    "> æ‚¨å¯ä»¥é€éå·¥ç ”é™¢æä¾›çš„ [NeuronPilot Porting Platform](https://neuronpilot-ai-porting-platform.azurewebsites.net/) ç·šä¸Šå¹³å°ï¼Œå°‡æ‚¨çš„ TensorFlow Lite æ¨¡å‹è½‰æ›ç‚º DLA æ ¼å¼ï¼š<br>**[NeuronPilot Platform]** > **[Upload Prebuilt Model]** > **[é¸æ“‡ TFLite æ¨¡å‹]** > **[Upload and Verify Model]** > **[é¸æ“‡é–‹ç™¼æ¿èˆ‡ Device]**> **[Download DLA]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ccd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mdla3.0'\n",
    "tflite_path = \"models/yolov8n_float32.tflite\"\n",
    "dla_path = \"models/yolov8n_float32_mdla3.dla\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99be2e",
   "metadata": {},
   "source": [
    "## 4. å»ºç«‹ NeuronRT Interpreter\n",
    "\n",
    "ä½¿ç”¨æˆ‘å€‘è‡ªè¨‚çš„ `utils.neuronpilot.neuronrt.Interpreter` é¡åˆ¥å»ºç«‹NeuronRT è§£é‡‹å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60221feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.neuronpilot.neuronrt import Interpreter\n",
    "\n",
    "interpreter = Interpreter(\n",
    "    tflite_path=tflite_path, \n",
    "    dla_path=dla_path, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"âœ… utils.neuronpilot.neuronrt.Interpreter å»ºç«‹å®Œæˆ\")\n",
    "print(f\"ğŸ”§ ä½¿ç”¨åŠ é€Ÿå™¨: {device.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a68ea",
   "metadata": {},
   "source": [
    "## 5. åˆå§‹åŒ– NeuronRT è§£é‡‹å™¨\n",
    "\n",
    "å»ºç«‹ NeuronRT è§£é‡‹å™¨ä¸¦é…ç½® AI æ¨¡å‹ã€‚\n",
    "1. åˆ†é…æ¨¡å‹æ‰€éœ€çš„è¨˜æ†¶é«”ç©ºé–“\n",
    "2. è¼‰å…¥ DLA æ¨¡å‹åˆ°æŒ‡å®šçš„åŠ é€Ÿå™¨\n",
    "3. å–å¾—æ¨¡å‹çš„è¼¸å…¥å’Œè¼¸å‡ºè³‡è¨Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec60b37-bf52-4454-8c27-0737fc18c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "input_dtype = input_details[0]['dtype']\n",
    "\n",
    "print(\"ğŸ“‹ æ¨¡å‹è³‡è¨Š:\")\n",
    "print(f\"   è¼¸å…¥å½¢ç‹€: {input_details[0]['shape']}\")\n",
    "print(f\"   è³‡æ–™å‹æ…‹: {input_details[0]['dtype']}\")\n",
    "print(f\"   è¼¸å‡ºå½¢ç‹€: {output_details[0]['shape']}\")\n",
    "print(f\"   è³‡æ–™å‹æ…‹: {output_details[0]['dtype']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e844b98",
   "metadata": {},
   "source": [
    "## 6. æº–å‚™è¼¸å…¥è³‡æ–™\n",
    "\n",
    "ç‚º AI æ¨¡å‹æº–å‚™æ¸¬è©¦ç”¨çš„è¼¸å…¥è³‡æ–™ã€‚\n",
    "1. æ ¹æ“šæ¨¡å‹è¦æ±‚çš„å½¢ç‹€ç”¢ç”Ÿéš¨æ©Ÿæ•¸å­—é™£åˆ—\n",
    "2. è½‰æ›è³‡æ–™å‹æ…‹ä»¥ç¬¦åˆæ¨¡å‹è¦æ ¼\n",
    "3. å°‡æº–å‚™å¥½çš„è³‡æ–™é€å…¥æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f238f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.rand(*input_details[0]['shape']).astype(input_details[0]['dtype'])\n",
    "\n",
    "print(f\"ğŸ“Š æ¸¬è©¦è³‡æ–™å½¢ç‹€: {inputs.shape}\")\n",
    "print(f\"ğŸ“Š æ¸¬è©¦è³‡æ–™å‹åˆ¥: {inputs.dtype}\")\n",
    "print(f\"ğŸ“Š æ¸¬è©¦è³‡æ–™ç¯„åœ: [{inputs.min():.3f}, {inputs.max():.3f}]\")\n",
    "\n",
    "interpreter.set_tensor(0, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28ed52",
   "metadata": {},
   "source": [
    "## 7. åŸ·è¡Œæ•ˆèƒ½åŸºæº–æ¸¬è©¦\n",
    "\n",
    "åŸ·è¡Œå¤šæ¬¡æ¨è«–ä¾†æ¸¬é‡æ¨¡å‹çš„å¹³å‡æ•ˆèƒ½ã€‚\n",
    "1. è¨­å®šæ¸¬è©¦çš„åŸ·è¡Œæ¬¡æ•¸\n",
    "2. è¨˜éŒ„æ¯æ¬¡æ¨è«–çš„åŸ·è¡Œæ™‚é–“\n",
    "3. è¨ˆç®—å¹³å‡æ•ˆèƒ½å’Œååé‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1297cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 10\n",
    "print(f\"é–‹å§‹åŸ·è¡Œ {iteration} æ¬¡æ¨è«–æ¸¬è©¦...\")\n",
    "inference_start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(iteration), desc=\"æ¨è«–é€²åº¦\", unit=\"æ¬¡\"):\n",
    "    interpreter.invoke()\n",
    "\n",
    "inference_end_time = time.time()\n",
    "outputs = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f8bea",
   "metadata": {},
   "source": [
    "## 7. é¡¯ç¤ºæ¸¬è©¦çµæœ\n",
    "\n",
    "è¨ˆç®—ä¸¦é¡¯ç¤º AI æ¨¡å‹çš„æ•ˆèƒ½æŒ‡æ¨™ã€‚\n",
    "1. è¨ˆç®—å¹³å‡å–®æ¬¡æ¨è«–æ™‚é–“ï¼ˆæ¯«ç§’ï¼‰\n",
    "2. è¨ˆç®—æ¨è«–ååé‡ï¼ˆæ¯ç§’è™•ç†æ¬¡æ•¸ï¼‰\n",
    "3. ä»¥è¡¨æ ¼æ ¼å¼é¡¯ç¤ºå®Œæ•´çš„æ•ˆèƒ½å ±å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inference_time = inference_end_time - inference_start_time\n",
    "avg_inference_time_ms = total_inference_time * 1000 / iteration\n",
    "\n",
    "print('=' * 50)\n",
    "print('TensorFlow Lite æ¨¡å‹æ•ˆèƒ½æ¸¬è©¦çµæœ')\n",
    "print('=' * 50)\n",
    "print(f'å–®æ¬¡æ¨è«–æ™‚é–“: {avg_inference_time_ms:.2f} ms')\n",
    "print(f'æ¨è«–ååé‡: {1000 / avg_inference_time_ms:.2f} FPS')\n",
    "print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb6f1c-0dbf-4d94-8917-c44d673beb2e",
   "metadata": {},
   "source": [
    "## 9. æ•´åˆåˆ°å¯¦éš›æ‡‰ç”¨\n",
    "\n",
    "æ‚¨å¯ä»¥åƒè€ƒä»¥ä¸‹çš„ç¨‹å¼ç¯„ä¾‹ï¼Œå°‡ArmNNåŠ é€Ÿæ–¹æ¡ˆæ•´åˆåˆ°æ‚¨çš„AIå·¥ä½œæµç¨‹ä¸­ã€‚\n",
    "\n",
    "```python\n",
    "from utils.neuronpilot.neuronrt import Interpreter\n",
    "\n",
    "interpreter = Interpreter(\n",
    "    tflite_path=\"<path_to your_tflite_model>\", \n",
    "    dla_path=\"<path_to_your_dla_model>\",       \n",
    "    device= \"<mdla3.0, mdla2.0 or vpu>\"\n",
    ")\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(0, test_input)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(0)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
