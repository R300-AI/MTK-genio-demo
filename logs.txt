[main] ÈñãÂßãËôïÁêÜÂΩ±Áâá: ./data/video.mp4
[inference] start
[inference] YOLO model loaded
[inference] got item from input_queue: 0
[inference] created predict task for frame 0
[predict] start: frame 0
[inference] got item from input_queue: 1
[inference] created predict task for frame 1
[predict] start: frame 1
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 2
[inference] created predict task for frame 2
[predict] start: frame 2
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 3
[inference] created predict task for frame 3
[predict] start: frame 3
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 4
[inference] created predict task for frame 4
[predict] start: frame 4
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 5
[inference] created predict task for frame 5
[predict] start: frame 5
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 6
[inference] created predict task for frame 6
[predict] start: frame 6
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 7
[inference] created predict task for frame 7
[predict] start: frame 7
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 8
[inference] created predict task for frame 8
[predict] start: frame 8
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
[inference] got item from input_queue: 9
[inference] created predict task for frame 9
[predict] start: frame 9
[inference] got item from input_queue: 10
[inference] created predict task for frame 10
[predict] start: frame 10
Ultralytics 8.3.175 üöÄ Python-3.12.2 torch-2.6.0+cpu CPU (Cortex-A55)
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
/home/ubuntu/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in
    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.
    See the [migration guide](https://ai.google.dev/edge/litert/migration)
    for details.
    
  warnings.warn(_INTERPRETER_DELETION_WARNING)
Successfully loaded NeuronRT delegate for DLA inference
/home/ubuntu/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in
    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.
    See the [migration guide](https://ai.google.dev/edge/litert/migration)
    for details.
    
  warnings.warn(_INTERPRETER_DELETION_WARNING)
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
Successfully loaded NeuronRT delegate for DLA inference
Load DLA model: ./models/yolov8n_float32.dla
[predict] done: frame 8
[predict] put to output_queue: frame 8
Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.
[inference] got item from input_queue: 11
                                         [inference] created predict task for frame 11
                                                                                      [predict] start: frame 11
                                                                                                               [predict] done: frame 1
[predict] put to output_queue: frame 1
[inference] got item from input_queue: 12
[inference] created predict task for frame 12
[predict] start: frame 12
[predict] done: frame 7
[predict] put to output_queue: frame 7
[inference] got item from input_queue: 13
[inference] created predict task for frame 13
[predict] start: frame 13
[predict] done: frame 6
[predict] put to output_queue: frame 6
[inference] got item from input_queue: 14
[inference] created predict task for frame 14
[predict] start: frame 14
[predict] done: frame 9
[predict] put to output_queue: frame 9

... ...
[inference] got item from input_queue: 107
[inference] created predict task for frame 107
[predict] start: frame 107
[predict] done: frame 97
[predict] put to output_queue: frame 97
[inference] got item from input_queue: 108
[inference] created predict task for frame 108
[predict] start: frame 108
[predict] done: frame 98
[predict] put to output_queue: frame 98
[inference] got item from input_queue: None
[inference] input_queue end signal received
[inference] end